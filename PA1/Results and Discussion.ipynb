{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the Assignment, two MLP's, 4-layers and 3-layers deep respectively, a kNN Classifier and a SVM have been trained using the MNIST Dataset. 5-fold cross Validation was used. The trends with respect to convergence and accuracy were studied and have been reported.\n",
    "\n",
    "**Note**: This document is intended to be only a discussion of the trends observed. All the data collected is presented with the other documents alongside the training code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training: \n",
    "\n",
    "The total dataset of 60000 images were split into 5 folds. 4 folds at a time were taken as the training set and the remaining fold was taken as the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 1, 2 and 3:\n",
    "\n",
    "The given architecture for a 4-layer MLP was implemented with Sigmoid and ReLU activation functions. They were trained using the method described above. \n",
    "\n",
    "Avg. Sigmoid Accuracy = 91.40 %\n",
    "Avg. ReLU Accuracy = 97.27 %\n",
    "\n",
    "The test error for ReLU is much lower when compared to Sigmoid. Learning rate decay might help Sigmoid to converge, especially during the later stages of training.\n",
    "\n",
    "## Observations:\n",
    "\n",
    "1. The convergence time for Sigmoid is much slower than ReLU - possibly due to the vanishing gradients in the case of Sigmoid.\n",
    "2. Usage of ReLU can sometimes lead to the exploding gradients problem which leads to numerical overflows. Often, this is the result of un-normalized inputs or parameters with high variances. Gradient Clipping comes handy in such scenarios.\n",
    "3. Often, ReLU neurons go dead, unlike Sigmoid neurons which can recover in the long-run.\n",
    "4. Occasionally, it was observed that the loss function kept oscillating during the later stages of training. Learning Rate Decay would help achieve better performance and smooth convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 4 and 5:\n",
    "\n",
    "In the first case, to make the task harder, instead of augmenting noisy data to the original data, the network was trained on noisy data and tested on regular data. \n",
    "L2 Regularisation was employed in another case with lambda=1e-3.\n",
    "\n",
    "Both cases used ReLU with the same architecture.\n",
    "Slight improvements are already observed over the normal cases in both the situations.\n",
    "\n",
    "Noisy ReLU Test Accuracy = 97.33 %\n",
    "L2-Regularized ReLU Test Accuracy = 97.18 %\n",
    "\n",
    "Note that this is on par with the ReLU Accuracy. On also training with regular data, the Noisy ReLU would perform much better. Imposing a heavier regularization might help in the second case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 6 and 7:\n",
    "\n",
    "HOG desciptors are suitable for this type of problems. HOG yields descriptors that are representative of the overall shape and the orientation of the image which are characteristic for digits. The drawback in this case is that the resolution of the dataset is low implying imprecise feature vectors. Given all that, it is remarkable that models simpler than the ones used above are competitive.\n",
    "\n",
    "A feature vector of length 81 is the condensed imaged vector  used in this portion.\n",
    "\n",
    "Models Compared:\n",
    "1. A 3-layer MLP with 500 and 250 hidden units, ReLU activation with Softmax outputs and Cross Entropy Loss.\n",
    "2. A kNN classifier with k=5.\n",
    "3. An Linear SVM (Using an RBF Kernel turned out to be computationally intractable)\n",
    "\n",
    "1. Avg. ReLU MLP Accuracy = 96.80 %\n",
    "2. Avg. Sigmoid MLP Accuracy = 96.81 %\n",
    "3. Avg. 5-NN Accuracy = 95.70 %\n",
    "4. Avg. Linear SVM Accuracy = 90.32 %\n",
    "\n",
    "## Observations:\n",
    "\n",
    "1. A smaller MLP compared to the earlier MLP performed competitively well on this task all thanks to the crafted feature vector. Necessitates the significance of representation.\n",
    "2. Surprisingly, the 5-NN classifier reported accuracies north of **95** percentage. \n",
    "3. The failure of the SVM could probably be due to similar local structures in the digits. An RBF kernel is obviously expected to perform a better job at classification.\n",
    "4. Dealing with a smaller model than earlier but the same number of iterations, both Sigmoid and ReLU models have converged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix and Top 3 Prediction Observations:\n",
    "\n",
    "Interestingly, the different algorithms used were \"confused\" differently when given the test set.\n",
    "\n",
    "### HOG-MLP: \n",
    "Digits that are oriented similarly were often confused in this category. Eg: 4 as 9 and 4 as 7 but not the opposite way.\n",
    "\n",
    "### KNN: \n",
    "Skeletally similar digits were confused here, naturally. Eg: 5 as 3 and vice-versa; 4 as 7 and vice-versa\n",
    "    \n",
    "### SVM:\n",
    "Often, dissimilar digits were confused. Eg: 3 as 2 and vice-versa. Interstingly, in one case, 1 was confused as 8.\n",
    "\n",
    "### Normal-MLP: \n",
    "Common error sets like (4,7,9) and (3, 5, 8) were predominant. Some peculiar trends can be found in individual folds which are probably the result of individual bias in each fold setting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
